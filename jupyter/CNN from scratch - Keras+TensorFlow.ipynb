{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN from scratch - Keras+TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for CNN models built from scratch, using Keras based on TensorFlow.\n",
    "First, some preparation work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, Activation, add\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from lib.data_utils import get_MNIST_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the MNIST data. Notice that we assume that it's 'kaggle-DigitRecognizer/data/train.csv', and we use helper function to read into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size:  (41000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# by default, there would be 41000 training data, 1000 test data and 1000 validation data(within traning set)\n",
    "data = get_MNIST_data()\n",
    "\n",
    "# see if we get the data correctly\n",
    "print('image size: ', data['X_train'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple CNN model using Keras and then train from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41000/41000 [==============================] - 213s - loss: 1.8055 - acc: 0.4786   \n",
      "Epoch 2/10\n",
      "41000/41000 [==============================] - 213s - loss: 1.3883 - acc: 0.6207   \n",
      "Epoch 3/10\n",
      "41000/41000 [==============================] - 212s - loss: 1.2307 - acc: 0.6574   \n",
      "Epoch 4/10\n",
      "41000/41000 [==============================] - 213s - loss: 1.1425 - acc: 0.6748   \n",
      "Epoch 5/10\n",
      "41000/41000 [==============================] - 213s - loss: 1.0881 - acc: 0.6867   \n",
      "Epoch 6/10\n",
      "41000/41000 [==============================] - 212s - loss: 1.0495 - acc: 0.6912   \n",
      "Epoch 7/10\n",
      "41000/41000 [==============================] - 213s - loss: 1.0120 - acc: 0.7006   \n",
      "Epoch 8/10\n",
      "41000/41000 [==============================] - 213s - loss: 0.9855 - acc: 0.7051   \n",
      "Epoch 9/10\n",
      "41000/41000 [==============================] - 213s - loss: 0.9633 - acc: 0.7124   \n",
      "Epoch 10/10\n",
      "41000/41000 [==============================] - 213s - loss: 0.9470 - acc: 0.7130   \n",
      "1000/1000 [==============================] - 1s     \n",
      "[0.79461298656463619, 0.82199999999999995]\n"
     ]
    }
   ],
   "source": [
    "# model architecture\n",
    "# [batchnorm-Conv-Conv-maxpool]x2 - [dense]x2 - [softmax]\n",
    "simple_CNN = Sequential()\n",
    "simple_CNN.add(BatchNormalization(input_shape=(28, 28, 1)))\n",
    "simple_CNN.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "simple_CNN.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "simple_CNN.add(MaxPooling2D((2, 2))) # (14,14,32)\n",
    "simple_CNN.add(Dropout(0.25))\n",
    "\n",
    "simple_CNN.add(BatchNormalization())\n",
    "simple_CNN.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "simple_CNN.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "simple_CNN.add(MaxPooling2D((2, 2))) # (7,7,64)\n",
    "simple_CNN.add(Dropout(0.25))\n",
    "\n",
    "simple_CNN.add(Flatten())\n",
    "simple_CNN.add(Dense(1024, activation='relu'))\n",
    "simple_CNN.add(Dropout(0.5))\n",
    "simple_CNN.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# set loss and optimizer\n",
    "rmsprop = RMSprop(lr=0.001, decay=0.99)\n",
    "simple_CNN.compile(loss='sparse_categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "simple_CNN.fit(data['X_train'], data['y_train'].reshape(-1,1), batch_size=64, epochs=10)\n",
    "\n",
    "# test the model and see accuracy\n",
    "score = simple_CNN.evaluate(data['X_test'], data['y_test'].reshape(-1, 1), batch_size=64)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the model: 0.822\n",
    "simple_CNN.save('simple_CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the small ResNet with 22 layers using Keras and train from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1280/41000 [..............................] - ETA: 672s - loss: 10.4792 - acc: 0.1914"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d189f134cad4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m mini_ResNet.fit(data['X_train'], data['y_train'].reshape(-1, 1), \n\u001b[0;32m     47\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                 callbacks=[checkpoint, plateau])\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# test the model and see accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1593\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1594\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1595\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1180\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1182\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1183\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2268\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2269\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2270\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2271\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model architecture\n",
    "# [Conv-batchnorm-relu]x4 - [residual: [Conv-batchnorm-relu]x2-Conv-batchnorm-add-relu]x6\n",
    "# 4\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(64, (7, 7), padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (1, 1), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(256, (1, 1), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "res = MaxPooling2D((2, 2))(x) # (14, 14, 64)\n",
    "\n",
    "# repeated residual modules\n",
    "for i in range(6): # 6x3 = 18\n",
    "    x = Conv2D(64, (1, 1), padding='same')(res)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(256, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = add([x, res])\n",
    "    res = Activation('relu')(x)\n",
    "\n",
    "x = GlobalAveragePooling2D(data_format='channels_last')(res) #(,256)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# connect the model\n",
    "mini_ResNet = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# set loss and optimizer\n",
    "rmsprop = RMSprop(lr=0.1, decay=0.9999)\n",
    "mini_ResNet.compile(loss='sparse_categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpoint = ModelCheckpoint('miniResNet_{epoch:02d}-{accuracy:.2f}.h5',\n",
    "                             monitor='accuracy',\n",
    "                             save_best_only=True)\n",
    "plateau = ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.0001)\n",
    "mini_ResNet.fit(data['X_train'], data['y_train'].reshape(-1, 1), \n",
    "                batch_size=32, epochs=10,\n",
    "                callbacks=[checkpoint, plateau])\n",
    "\n",
    "# test the model and see accuracy\n",
    "score = mini_ResNet.evaluate(data['X_test'], data['y_test'].reshape(-1, 1), batch_size=32)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model: 0.903\n",
    "mini_ResNet.save('mini_ResNet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Simple CNN with residual connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Inspired by ResNet, we try to add residual connections to the simple CNN model above and see if there exists difference of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41000/41000 [==============================] - 160s - loss: 1.8254 - acc: 0.4948   \n",
      "Epoch 2/10\n",
      "41000/41000 [==============================] - 163s - loss: 1.7300 - acc: 0.5707   \n",
      "Epoch 3/10\n",
      "41000/41000 [==============================] - 158s - loss: 1.6971 - acc: 0.5880   \n",
      "Epoch 4/10\n",
      "41000/41000 [==============================] - 159s - loss: 1.6766 - acc: 0.6003   \n",
      "Epoch 5/10\n",
      "41000/41000 [==============================] - 163s - loss: 1.6600 - acc: 0.6059   \n",
      "Epoch 6/10\n",
      "41000/41000 [==============================] - 163s - loss: 1.6477 - acc: 0.6134   \n",
      "Epoch 7/10\n",
      "41000/41000 [==============================] - 159s - loss: 1.6371 - acc: 0.6200   \n",
      "Epoch 8/10\n",
      "41000/41000 [==============================] - 156s - loss: 1.6282 - acc: 0.6242   \n",
      "Epoch 9/10\n",
      "41000/41000 [==============================] - 160s - loss: 1.6209 - acc: 0.6287   \n",
      "Epoch 10/10\n",
      "41000/41000 [==============================] - 159s - loss: 1.6148 - acc: 0.6316   \n",
      "1000/1000 [==============================] - 1s     \n",
      "[1.5642967071533203, 0.66699999904632568]\n"
     ]
    }
   ],
   "source": [
    "# model architecture\n",
    "# [Conv] - [batchnorm-Conv-Conv-add-maxpool]x2 - [dense]x2 - [softmax]\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = Conv2D(64, (7, 7), activation='relu', padding='same')(inputs)\n",
    "\n",
    "res = BatchNormalization()(x) # (28, 28, 64)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(res)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = add([res, x])\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "res = BatchNormalization()(x) # (14, 14, 64)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(res)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = add([res, x])\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "simple_resCNN = Model(inputs=inputs,outputs=predictions)\n",
    "\n",
    "# set loss and optimizer\n",
    "rmsprop = RMSprop(lr=0.001, decay=0.99)\n",
    "simple_resCNN.compile(loss='sparse_categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "simple_resCNN.fit(data['X_train'], data['y_train'].reshape(-1,1), batch_size=64, epochs=10)\n",
    "\n",
    "# test the model and see accuracy\n",
    "score = simple_resCNN.evaluate(data['X_test'], data['y_test'].reshape(-1, 1), batch_size=64)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
