{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional methods - OpenCV+scikit_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's for traditional methods of object detection, using OpenCV to preprocess and extract features and then use machine learning algorithm to classify. \n",
    "Generally, it can be divided into three modules: preprocessing, feature extraction and classification.\n",
    "First, some prepration works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lib.data_utils import get_MNIST_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then read the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "data = get_MNIST_data(subtract_mean=False)\n",
    "\n",
    "# check if we load the data successfully\n",
    "print(data['X_train'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different methods exist to extract feature. Here we try ORB (Oriented FAST and Rotated BRIEF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum number of keypoints: 11\n"
     ]
    }
   ],
   "source": [
    "# check the min number of keypoints\n",
    "orb = cv2.ORB_create(edgeThreshold=2, patchSize=2)\n",
    "len_k = 500\n",
    "for key in ['X_train', 'X_test']:\n",
    "    for img in data[key]:\n",
    "        k = orb.detect(img.astype(np.uint8).reshape((28,28)))\n",
    "        if len(k) < len_k:\n",
    "            len_k = len(k)\n",
    "print('minimum number of keypoints:', len_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute for data:  X_test\n",
      "compute for data:  X_train\n"
     ]
    }
   ],
   "source": [
    "# compute the ORB descriptors\n",
    "feats = {'X_train': np.zeros((41000,len_k*32)), 'X_test': np.zeros((1000,len_k*32))}\n",
    "for key in feats.keys():\n",
    "    print('compute for data: ', key)\n",
    "    for i, img in zip(range(data[key].shape[0]), data[key]):\n",
    "        k = orb.detect(img.astype(np.uint8).reshape((28,28)))\n",
    "        _, feat = orb.compute(img.astype(np.uint8).reshape((28,28)), k[:len_k])\n",
    "        feats[key][i,:] = feat.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41000, 352)\n",
      "(1000, 352)\n"
     ]
    }
   ],
   "source": [
    "# check the computed features size\n",
    "print(feats['X_train'].shape)\n",
    "print(feats['X_test'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try HOG (Histogram of Oriented Gradients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute for data:  X_test\n",
      "compute for data:  X_train\n"
     ]
    }
   ],
   "source": [
    "# compute the HOG for each image\n",
    "feats = {'X_train': [], 'X_test': []}\n",
    "for key in feats.keys():\n",
    "    print('compute for data: ', key)\n",
    "    for img in data[key]:\n",
    "        feat = hog(img.reshape((28,28)),\n",
    "                   pixels_per_cell=(7,7),\n",
    "                   cells_per_block=(4,4),\n",
    "                   block_norm='L2-Hys')\n",
    "        feats[key].append(feat.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41000, 144)\n",
      "(1000, 144)\n"
     ]
    }
   ],
   "source": [
    "feats['X_train'] = np.array(feats['X_train'])\n",
    "feats['X_test'] = np.array(feats['X_test'])\n",
    "# check the computed features size\n",
    "print(feats['X_train'].shape)\n",
    "print(feats['X_test'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to use PCA to reduce dimensions of feature to avoid curse of dimensionality for common classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize PCA with top 50\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(feats['X_train'])\n",
    "feats_reduce = {'X_train': [], 'X_test': []}\n",
    "for key in feats.keys():\n",
    "    feats_reduce[key] = pca.transform(feats[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41000, 50)\n",
      "(1000, 50)\n"
     ]
    }
   ],
   "source": [
    "# check the computed features size\n",
    "print(feats_reduce['X_train'].shape)\n",
    "print(feats_reduce['X_test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different machine learning methods are used to classify the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.903\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(feats['X_train'],data['y_train'])\n",
    "print(dt.score(feats['X_test'], data['y_test']))\n",
    "# test accuracy of 57.2% using ORB\n",
    "# test accuracy of 90.2% using HOG (7, 2)\n",
    "# test accuracy of 90.3% using HOG (7, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n"
     ]
    }
   ],
   "source": [
    "# decision tree for reduced data\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(feats_reduce['X_train'],data['y_train'])\n",
    "print(dt.score(feats_reduce['X_test'], data['y_test']))\n",
    "# test accuracy of 89% using HOG (7, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607\n"
     ]
    }
   ],
   "source": [
    "# k nearest neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(feats['X_train'],data['y_train'])\n",
    "print(knn.score(feats['X_test'], data['y_test']))\n",
    "# test accuracy of 29.9% using ORB\n",
    "# test accuracy of 94.2% using HOG (7, 2)\n",
    "# test accuracy of 97.3% using HOG (7, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n"
     ]
    }
   ],
   "source": [
    "# k nearest neighbors for reduced data\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(feats_reduce['X_train'],data['y_train'])\n",
    "print(knn.score(feats_reduce['X_test'], data['y_test']))\n",
    "# test accuracy of 94% using HOG (7, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(feats['X_train'],data['y_train'])\n",
    "print(rf.score(feats['X_test'], data['y_test']))\n",
    "# test accuracy of 59.6% using ORB\n",
    "# test accuracy of 96% using HOG (7, 2)\n",
    "# test accuracy of 94.3% using HOG (8, 3)\n",
    "# test accuracy of 96% using HOG (7, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm = SVC()\n",
    "svm.fit(feats['X_train'],data['y_train'])\n",
    "print(svm.score(feats['X_test'], data['y_test']))\n",
    "# test accuracy of 51.1% using ORB\n",
    "# test accuracy of 11.5% using HOG (7, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
